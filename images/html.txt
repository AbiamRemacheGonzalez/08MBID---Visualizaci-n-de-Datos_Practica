<div id="app">
  <span class="negrita">Nombre:</span> Abiam Remache González
  <br />
  <span class="negrita">URL:</span
  ><a href="https://js-sp2aft.stackblitz.io/">Página web</a>
  <br />
  <span class="negrita">GitHub:</span
  ><a
    href="https://github.com/AbiamRemacheGonzalez/08MBID---Visualizaci-n-de-Datos_Practica.git"
    >Código fuente</a
  >

  <h1>Actividad práctica 1</h1>
  <h2>Introducción</h2>
  <p>
    Para este proyecto se ha elegido hacer un estudio previo para tomar
    decisiones para nuestro Trabajo de Final de Máster. El trabajo de final de
    máster elegido tiene como objetivo la detección de un esqueleto de animales
    a través de una imagen utilizando un modelo de DeepLearning.
  </p>
  <p>
    Hemos decidido utilizar un conjunto de datos que ya está etiquetado. El
    conjunto de datos tiene 4215 imágenes de 181x181 pixeles en blanco y negro
    de moscas de fruta. Estas primeras imágenes se usarán para el entrenamiento,
    adicionalmente hay otras 1800 imágenes para la prueba. Además, cada conjunto
    de datos tiene un fichero json que tiene anotado por cada imagen la
    localización de 17 puntos claves, correspondientes con la cabeza, el tórax y
    las extremidades de la mosca. Estos puntos nos servirán para saber que tan
    bien está detectando los puntos claves nuestra red neuronal durante el
    proceso de entrenamiento.
  </p>
  <p>Estudiaremos el desempeño de la red UNET56 utilizando cuatro métodos de optimización distintos durante 5 épocas de entrenamiento, con el fin de seleccionar el mejor método de optimización. Todos los experimentos se realizarán bajo las mismas condiciones de hiperparámetros:
    <ul><li>Épocas = 5</li><li>Tamaño del batch = 32</li>
    <li>Learning rate = 1e-2</li><li>Modelo de red = UNET56</li>
    </ul>
  </p>
  <p>El objetivo de la red neuronal es la estimación de 17 puntos claves de una imagen dada. Para medir el desempeño de la red con los diferentes métodos de optimización haremos uso de tres métricas:
    <ul><li><a href=https://es.wikipedia.org/wiki/Funci%C3%B3n_de_p%C3%A9rdida >Loss o función de coste</a></li><li><a href=https://docs.oracle.com/cloud/help/es/pbcs_common/PFUSU/insights_metrics_RMSE.htm#PFUSU-GUID-FD9381A1-81E1-4F6D-8EC4-82A6CE2A6E74 >Error de raíz cuadrada media. (RMSE)</a></li>
      <li><a href="https://www.v7labs.com/blog/human-pose-estimation-guide#:~:text=Human%20Pose%20Estimation%20(HPE)%20is,is%20known%20as%20a%20pair">Porcentaje de puntos claves identificados correctamente. (PCK) </a></li>
      </ul>
  </p>
  <p>Los métodos de optimización elegidos son:
    <ul><li><a href=https://scikit-learn.org/stable/modules/sgd.html>-	Stochastic Gradient Descent (SGD)</a></li><li><a href=https://machinelearningmastery.com/gradient-descent-with-momentum-from-scratch>-	Stochastic Grandient Descent with Momentum (SGD_M)</a></li>
      <li><a href="https://optimization.cbe.cornell.edu/index.php?title=RMSProp#:~:text=RMSProp%2C%20root%20mean%20squared%20propagation,of%20gradients%20descent%20and%20RProp">Root Mean Square Propagation (RMSP)</a></li>
      <li><a href="https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/">Adam (ADAM)</a></li>
      </ul>
  </p>
  <p>En anteriores proyectos he tenido la posibilidad de comparar estos métodos de optimización probando en redes convolucionales sencillas donde hacíamos clasificación de imágenes de números usando el conjunto de datos MNIST. El experimento consistía en ver cuantas épocas de entrenamiento hacían falta para llegar a un 95% de precisión, los resultados fueron: 116 épocas para el método SGD, 11 épocas para SGD with momentum, 5 épocas para RMSP y 2 épocas para ADAM.</p>
  <p>
    Dicho esto, los objetivos concretos de este proyecto son:
    <ul>
      <li>Realizar los cuatro experimentos y recopilar datos.</li>
      <li>Observar gráficamente la evolución por batchs y épocas de nuestros cuatro experimentos.</li>
      <li>Evaluar el desempeño de nuestros modelos y elegir el método de optimización que mejor funcione.</li>
      <li>Reentrenar nuestro modelo por 15 épocas y visualizar la distribución de error por cada uno de los puntos.</li>
    </ul>
  </p>
  <p>
    Las herramientas que se va a utilizar son:
    <ul>
      <li>Python para entrenar las redes y recopilar datos.</li>
      <li>Power Bi para el muestreo de los datos de los cuatro experimentos.</li>
      <li>Finalmente se harán unas gráficas usando Python para ver la distribución de los errores cometidos por cada uno de los puntos.</li>
    </ul>
  </p>
  
  <h2>Metodología</h2>
  <p>
    El proyecto tiene varias partes bien definidas:
    <ul>
      <li>Entrenamiento de la red neuronal para los cuatro métodos de optimización.</li>
      <li>Recopilación de datos de los experimentos</li>
      <li>Hacer gráficas comparativas de los cuatro experimentos</li>
      <li>Elegir un método de optimización en base a los resultados</li>
      <li>Reentrenar el modelo con el método elegido</li>
      <li>Visualizar distribución de errores</li>
    </ul>
  </p>
  <h3>Entrenamiento de la red neuronal</h3>
  <p>Para el entrenamiento de la red neuronal haremos uso del framework pytorch y usaremos el modelo de red neuronal Unet56. Los hiperparámetros elegidos para los cuatro experimentos son 5 épocas, 32 imágenes de tamaño de minibatch y 1e-2 de índice de aprendizaje. Los parámetros para los optimizadores serán los valores por defecto. En total el entrenamiento de los 4 experimentos duró dos horas y media, se entrenó con un total de 4215 imágenes.</p>
  <h3>Recopilación de datos</h3>
  <p>
    Durante el entrenamiento se recuperaron los siguientes datos por cada batch del entrenamiento
    <ul>
      <li>Número del experimento</li>
      <li>Número de época</li>
      <li>Número de batch</li>
      <li>Loss para el entrenamiento</li>
      <li>PCK para el entrenamiento</li>
      <li>Error para el entrenamiento</li>
      <li>Loss para la evaluación</li>
      <li>PCK para la evaluación</li>
      <li>Error para la evaluación</li>
      <li>PCK para cada uno de los 17 puntos estimados</li>
      <li>El Error para cada uno de los 17 puntos estimados</li>
    </ul>
  </p>
  <p>En total se recopilaron 43 características para un total de 2380 registros, 595 registros por cada experimento. El resultado de este procedimiento son cuatro ficheros CSV con 595 registros cada uno.
  </p>
  <h3>Gráficas en Power Bi</h3>
  <p>Inicialmente se adaptaron algunos tipos y corrigieron algunos problemas con el tipo decimal. Esto es debido a que la librería panda que estaba guardando los datos en los ficheros csv usaba puntos para los decimales y power Bi no reconocía los decimales. Adicionalmente se juntaron los cuatro ficheros en uno solo con la opción de anexar consultas de power Bi. Tras esos pequeños cambios pudimos jugar con los datos y mostrarlos mediante gráficas.</p>
  <p>Se hará en primer lugar un análisis del desempeño de la red neuronal para los cuatro experimentos por época de entrenamiento. En este primer análisis seremos capaces de visualizar el desempeño para conjunto de datos de entrenamiento y para el conjunto de datos de evaluación. Las métricas que vamos a usar para medir el desempeño son el valor de “Loss” y el valor de “PCK” o “Porcentaje de Puntos Clave Correctamente Identificados”. En toda ocasión se mostrarán valores promedios por época y experimento.</p>
  <p>Para el análisis del desempeño de la red neuronal para los cuatro experimentos se hará uso de dos gráficas lineales que visualizan a la vez el valor del PCK y el valor del Loss, una gráfica para los resultados del desempeño en el conjunto de datos de evaluación y otra gráfica para el conjunto de datos de entrenamiento. Para poder hacer un análisis más dinámico se dispondrá de dos filtros, uno que filtrará por experimento y otro que filtrará por época de entrenamiento. Adicionalmente, en dos cuadros en grande se podrá visualizar el valor promedio para el PCK y el Loss, con los filtros aplicados.</p>
  <p>En segundo lugar, analizaremos el desempeño de la red neuronal para los tres puntos correspondientes a la cabeza, correspondientes a punto 0, 1 y 2. En esta ocasión mediremos el desempeño de la red en la estimación de estos 3 puntos clave, debido a que se trata de una parte clave que necesitamos estimar correctamente. Las métricas usadas para medir el desempeño son el “Error” o “RMSE” y el “PCK” o “Porcentaje de Puntos Clave Correctamente Identificados”.</p>
  <p>Para el análisis del desempeño de la red neuronal para los tres puntos correspondientes a la cabeza durante el entrenamiento, se hará uso de dos gráficas de barras una que mide el desempeño usando la métrica PCK y otra gráfica que mide el desempeño usando la métrica Error. Cada una de las barras indicará el valor de PCK o Error para uno de los tres puntos de la cabeza. El valor de las métricas podrá visualizarse a lo largo de las épocas de entrenamiento. Adicionalmente se añade una línea que indica la tendencia de los valores de PCK y Error según el promedio de la población.</p>
  <h3>Elección del método de optimización</h3>
  <p>Para la elección el método de optimización analizaremos las graficas resultantes del anterior procedimiento, buscando la maximización del valor para la métrica “PCK” y buscando la minimización del valor de las métricas de “Loss” y “Error”. El método elegido será usado para el reentrenamiento de la red neuronal bajo las mismas condiciones, pero dejando entrenar el modelo hasta 15 épocas.</p>
  <h3>Visualización de la distribución de errores</h3>
  <p>En este último apartado queremos observar una comparativa de la distribución de los errores para una red neuronal sin entrenamiento y con entrenamiento. Este experimento tiene como objetivo la compresión de la distribución de errores antes y después de un entrenamiento bueno, para el conjunto de datos de entrenamiento y evaluación. Se trata de una gráfica de líneas donde cada línea representa un conjunto de entrenamiento concreto.</p>
  <p>Se generan 17 gráficas donde se dispondrán visualmente la distribución de los errores para cada uno de los 17 puntos que nuestra red neuronal tiene que identificar. La metodología consiste en usar la función histrogram de numpy con la opción densidad activada. Como resultado representaremos en el eje x el rango posible en el que se distribuye el error y en el eje y la probabilidad de densidad de que un error pertenezca a ese rango de error.</p>
  <h2>Resultados</h2>
  <p>
    <iframe title="Report Section" width="1000" height="600" src="https://app.powerbi.com/view?r=eyJrIjoiYTM3ZWQ4OTItMzVmZC00ZGE3LThhNGItY2YxY2VhMTM5ZTY5IiwidCI6ImIyYmI3MzFjLTQ2MGQtNDIwZi1hNDc1LTNlZDYxNWE4Mjk4NyIsImMiOjh9" frameborder="0" allowFullScreen="true"></iframe>
  </p>
  <p></p>
  <h2>Conclusión</h2>
</div>
