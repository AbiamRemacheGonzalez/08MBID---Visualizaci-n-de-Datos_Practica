<div id="app">
  <span class="negrita">Nombre:</span> Abiam Remache González
  <br />
  <span class="negrita">URL:</span
  ><a href="https://js-sp2aft.stackblitz.io/">Página web</a>
  <br />
  <span class="negrita">GitHub:</span
  ><a
    href="https://github.com/AbiamRemacheGonzalez/08MBID---Visualizaci-n-de-Datos_Practica.git"
    >Código fuente</a
  >

  <h1>Actividad práctica 1</h1>
  <h2>Introducción</h2>
  <p>
    Para este proyecto se ha elegido hacer un estudio previo para tomar
    decisiones para nuestro Trabajo de Final de Máster. El trabajo de final de
    máster elegido tiene como objetivo la detección de un esqueleto de animales
    a través de una imagen utilizando un modelo de DeepLearning.
  </p>
  <p>
    Hemos decidido utilizar un conjunto de datos que ya está etiquetado. El
    conjunto de datos tiene 4215 imágenes de 181x181 pixeles en blanco y negro
    de moscas de fruta. Estas primeras imágenes se usarán para el entrenamiento,
    adicionalmente hay otras 1800 imágenes para la prueba. Además, cada conjunto
    de datos tiene un fichero json que tiene anotado por cada imagen la
    localización de 17 puntos claves, correspondientes con la cabeza, el tórax y
    las extremidades de la mosca. Estos puntos nos servirán para saber que tan
    bien está detectando los puntos claves nuestra red neuronal durante el
    proceso de entrenamiento.
  </p>
  <p>Estudiaremos el desempeño de la red UNET56 utilizando cuatro métodos de optimización distintos durante 5 épocas de entrenamiento, con el fin de seleccionar el mejor método de optimización. Todos los experimentos se realizarán bajo las mismas condiciones de hiperparámetros:
    <ul><li>Épocas = 5</li><li>Tamaño del batch = 32</li>
    <li>Learning rate = 1e-2</li><li>Modelo de red = UNET56</li>
    </ul>
  </p>
  <p>El objetivo de la red neuronal es la estimación de 17 puntos claves de una imagen dada. Para medir el desempeño de la red con los diferentes métodos de optimización haremos uso de tres métricas:
    <ul><li><a href=https://es.wikipedia.org/wiki/Funci%C3%B3n_de_p%C3%A9rdida >Loss o función de coste</a></li><li><a href=https://docs.oracle.com/cloud/help/es/pbcs_common/PFUSU/insights_metrics_RMSE.htm#PFUSU-GUID-FD9381A1-81E1-4F6D-8EC4-82A6CE2A6E74 >Error de raíz cuadrada media. (RMSE)</a></li>
      <li><a href="https://www.v7labs.com/blog/human-pose-estimation-guide#:~:text=Human%20Pose%20Estimation%20(HPE)%20is,is%20known%20as%20a%20pair">Porcentaje de puntos claves identificados correctamente. (PCK) </a></li>
      </ul>
  </p>
  <p>Los métodos de optimización elegidos son:
    <ul><li><a href=https://scikit-learn.org/stable/modules/sgd.html>-	Stochastic Gradient Descent (SGD)</a></li><li><a href=https://machinelearningmastery.com/gradient-descent-with-momentum-from-scratch>-	Stochastic Grandient Descent with Momentum (SGD_M)</a></li>
      <li><a href="https://optimization.cbe.cornell.edu/index.php?title=RMSProp#:~:text=RMSProp%2C%20root%20mean%20squared%20propagation,of%20gradients%20descent%20and%20RProp">Root Mean Square Propagation (RMSP)</a></li>
      <li><a href="https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/">Adam (ADAM)</a></li>
      </ul>
  </p>
  <p>En anteriores proyectos he tenido la posibilidad de comparar estos métodos de optimización probando en redes convolucionales sencillas donde hacíamos clasificación de imágenes de números usando el conjunto de datos MNIST. El experimento consistía en ver cuantas épocas de entrenamiento hacían falta para llegar a un 95% de precisión, los resultados fueron: 116 épocas para el método SGD, 11 épocas para SGD with momentum, 5 épocas para RMSP y 2 épocas para ADAM.</p>
  <p>
    Dicho esto, los objetivos concretos de este proyecto son:
    <ul>
      <li>Realizar los cuatro experimentos y recopilar datos.</li>
      <li>Observar gráficamente la evolución por batchs y épocas de nuestros cuatro experimentos.</li>
      <li>Evaluar el desempeño de nuestros modelos y elegir el método de optimización que mejor funcione.</li>
      <li>Reentrenar nuestro modelo por 15 épocas y visualizar la distribución de error por cada uno de los puntos.</li>
    </ul>
  </p>
  <p>
    Las herramientas que se va a utilizar son:
    <ul>
      <li>Python para entrenar las redes y recopilar datos.</li>
      <li>Power Bi para el muestreo de los datos de los cuatro experimentos.</li>
      <li>Finalmente se harán unas gráficas usando Python para ver la distribución de los errores cometidos por cada uno de los puntos.</li>
    </ul>
  </p>
  
  <h2>Metodología</h2>
  <p>
    El proyecto tiene varias partes bien definidas:
    <ul>
      <li>Entrenamiento de la red neuronal para los cuatro métodos de optimización.</li>
      <li>Recopilación de datos de los experimentos</li>
      <li>Hacer gráficas comparativas de los cuatro experimentos</li>
      <li>Elegir un método de optimización en base a los resultados</li>
      <li>Reentrenar el modelo con el método elegido</li>
      <li>Visualizar distribución de errores</li>
    </ul>
  </p>
  <h3>Entrenamiento de la red neuronal</h3>
  <p>Para el entrenamiento de la red neuronal haremos uso del framework pytorch y usaremos el modelo de red neuronal Unet56. Los hiperparámetros elegidos para los cuatro experimentos son 5 épocas, 32 imágenes de tamaño de minibatch y 1e-2 de índice de aprendizaje. Los parámetros para los optimizadores serán los valores por defecto. En total el entrenamiento de los 4 experimentos duró dos horas y media, se entrenó con un total de 4215 imágenes.</p>
  <h3>Recopilación de datos</h3>
  <p>
    Durante el entrenamiento se recuperaron los siguientes datos por cada batch del entrenamiento
    <ul>
      <li>Número del experimento</li>
      <li>Número de época</li>
      <li>Número de batch</li>
      <li>Loss para el entrenamiento</li>
      <li>PCK para el entrenamiento</li>
      <li>Error para el entrenamiento</li>
      <li>Loss para la evaluación</li>
      <li>PCK para la evaluación</li>
      <li>Error para la evaluación</li>
      <li>PCK para cada uno de los 17 puntos estimados</li>
      <li>El Error para cada uno de los 17 puntos estimados</li>
    </ul>
  </p>
  <p>En total se recopilaron 43 características para un total de 2380 registros, 595 registros por cada experimento. El resultado de este procedimiento son cuatro ficheros CSV con 595 registros cada uno.
  </p>
  <h3>Gráficas en Power Bi</h3>
  <p>Inicialmente se adaptaron algunos tipos y corrigieron algunos problemas con el tipo decimal. Esto es debido a que la librería panda que estaba guardando los datos en los ficheros csv usaba puntos para los decimales y power Bi no reconocía los decimales. Adicionalmente se juntaron los cuatro ficheros en uno solo con la opción de anexar consultas de power Bi. Tras esos pequeños cambios pudimos jugar con los datos y mostrarlos mediante gráficas.</p>
  <p>Se hará en primer lugar un análisis del desempeño de la red neuronal para los cuatro experimentos por época de entrenamiento. En este primer análisis seremos capaces de visualizar el desempeño para conjunto de datos de entrenamiento y para el conjunto de datos de evaluación. Las métricas que vamos a usar para medir el desempeño son el valor de “Loss” y el valor de “PCK” o “Porcentaje de Puntos Clave Correctamente Identificados”. En toda ocasión se mostrarán valores promedios por época y experimento.</p>
  <p>Para el análisis del desempeño de la red neuronal para los cuatro experimentos se hará uso de dos gráficas lineales que visualizan a la vez el valor del PCK y el valor del Loss, una gráfica para los resultados del desempeño en el conjunto de datos de evaluación y otra gráfica para el conjunto de datos de entrenamiento. Para poder hacer un análisis más dinámico se dispondrá de dos filtros, uno que filtrará por experimento y otro que filtrará por época de entrenamiento. Adicionalmente, en dos cuadros en grande se podrá visualizar el valor promedio para el PCK y el Loss, con los filtros aplicados.</p>
  <p>En segundo lugar, analizaremos el desempeño de la red neuronal para los tres puntos correspondientes a la cabeza, correspondientes a punto 0, 1 y 2. En esta ocasión mediremos el desempeño de la red en la estimación de estos 3 puntos clave, debido a que se trata de una parte clave que necesitamos estimar correctamente. Las métricas usadas para medir el desempeño son el “Error” o “RMSE” y el “PCK” o “Porcentaje de Puntos Clave Correctamente Identificados”.</p>
  <p>Para el análisis del desempeño de la red neuronal para los tres puntos correspondientes a la cabeza durante el entrenamiento, se hará uso de dos gráficas de barras una que mide el desempeño usando la métrica PCK y otra gráfica que mide el desempeño usando la métrica Error. Cada una de las barras indicará el valor de PCK o Error para uno de los tres puntos de la cabeza. El valor de las métricas podrá visualizarse a lo largo de las épocas de entrenamiento. Adicionalmente se añade una línea que indica la tendencia de los valores de PCK y Error según el promedio de la población.</p>
  <h3>Elección del método de optimización</h3>
  <p>Para la elección el método de optimización analizaremos las graficas resultantes del anterior procedimiento, buscando la maximización del valor para la métrica “PCK” y buscando la minimización del valor de las métricas de “Loss” y “Error”. El método elegido será usado para el reentrenamiento de la red neuronal bajo las mismas condiciones, pero dejando entrenar el modelo hasta 15 épocas.</p>
  <h3>Visualización de la distribución de errores</h3>
  <p>En este último apartado queremos observar una comparativa de la distribución de los errores para una red neuronal sin entrenamiento y con entrenamiento. Este experimento tiene como objetivo la compresión de la distribución de errores antes y después de un entrenamiento bueno, para el conjunto de datos de entrenamiento y evaluación. Se trata de una gráfica de líneas donde cada línea representa un conjunto de entrenamiento concreto.</p>
  <p>Se generan 17 gráficas donde se dispondrán visualmente la distribución de los errores para cada uno de los 17 puntos que nuestra red neuronal tiene que identificar. La metodología consiste en usar la función histrogram de numpy con la opción densidad activada. Como resultado representaremos en el eje x el rango posible en el que se distribuye el error y en el eje y la probabilidad de densidad de que un error pertenezca a ese rango de error.</p>
  <h2>Resultados</h2>
  <h3>Cuadro de mandos</h3>
  <p>
    <iframe title="Report Section" width="1000" height="600" src="https://app.powerbi.com/view?r=eyJrIjoiYTM3ZWQ4OTItMzVmZC00ZGE3LThhNGItY2YxY2VhMTM5ZTY5IiwidCI6ImIyYmI3MzFjLTQ2MGQtNDIwZi1hNDc1LTNlZDYxNWE4Mjk4NyIsImMiOjh9" frameborder="0" allowFullScreen="true"></iframe>

    
  </p>
  <p>En la gráfica dinámica de Power Bi tenemos dos páginas.</p>
  <p>En la primera página con título “Análisis del desempeño de la red con diferentes métodos de optimización” se hace un análisis del PCK frente al loss por cada batch de entrenamiento. Podemos filtrar por experimento y por época de entrenamiento. Adicionalmente podemos ver un promedio que nos ayudará a ver el desempeño tanto en Porcentaje de puntos clave detectados correctamente como el valor de Loss.</p>
  <p>En la gráfica de la izquierda vemos el desempeño de la red neuronal para la evaluación. En general los valores de PCK aumentan a medida que el valor de Loss disminuye. Nuestra red neuronal esta generalizando correctamente. </p>
  <p>En la gráfica de la derecha vemos el desempeño de la red neuronal para el entrenamiento. Observamos un comportamiento similar al de la recta de la izquierda.</p>
  <p>Se puede observar que el mejor optimizador con diferencia es el SGD con Momentum alcanzando un 87% de PCK de promedio y en su última epoch un 94.6% para el conjunto de datos de evaluación. Los demás experimentos no ascienden de 70% de PCK y los valores de Loss son significativamente mayores.</p>
  <p>Otra observación remarcable es que RMSP tiene un desempeño malísimo no superando el 10% de PCK en su última época.</p>
  <p>Por lo tanto, el método de optimización que mejor desempeño tiene es el SGD con Momentum y es que se usará para la comparativa en la distribución de errores.</p>
  <p>En la segunda página con título “Análisis del desempeño de la red en la estimación de los puntos de la cabeza durante el entrenamiento” analizamos el desempeño de la red neuronal al estimar la posición de tres puntos clave correspondientes a la cabeza de la mosca de la fruta. En esta ocasión también disponemos de un filtro que nos ayudará a elegir entre los diferentes experimentos realizados.</p>
  <p>En la gráfica lineal de la derecha visualizamos como el error en las estimaciones para los tres puntos en general disminuye, eso significa que en efecto nuestra red neuronal esta aprendiendo a identificar correctamente los puntos. La línea en lila nos muestra si los errores cometidos están por encima o por debajo de la media.</p>
  <p>En la gráfica lineal de la izquierda visualizamos el porcentaje de puntos claves correctamente identificados para los tres puntos que estamos analizando. La línea en lila nos muestra si el porcentaje de PCK está por encima o por debajo del promedio.</p>
  <p>De este pequeño experimento podemos deducir que nuestra red está decrementando correctamente los errores para nuestro experimento SGD con momentum y además que se están estimando correctamente la totalidad de los puntos durante el entrenamiento casi desde la primera época. Con este segundo experimento reforzamos nuestra decisión tomada en el anterior apartado y además visualizamos información relevante de los tres puntos que se consideran más importantes en nuestra predicción.</p>
  <h3>Distribución de errores</h3>
  <p>Utilizando la librería de Python matplotlib.pyplot haremos el graficado de la distribución de error de los 17 puntos clave que nuestra red neuronal ha estimado. Para no saturar con tantas imágenes hemos decidido elegir un único punto (el del tórax) y visualizar su distribución. Los demás resultados estarán el github para su visualiación con el nombre de train15.png y notrain.png</p>
  <p>A grandes rasgos recuperamos un conjunto de errores en la estimación usando RMSE donde usamos el valor real y el estimado para calcular el error para todas las imágenes del conjunto de datos. Posteriormente se calcula el rango de la distribución usando el percentil 99, mediante la función histogram de numpy calculamos para cada uno de los 17 puntos su distribución a lo largo de todos los rangos de la distribución y finalmente graficamos usando pyplot.</p>
  <h4>Gráfica modelo sin entrenar</h4>
  <img src="https://i.postimg.cc/QdN96K5q/tejn.png" height="600px" width="800px"></p>
  Para eset punto concreto los errores son muy grandes y está fundamentalmente focalizados entre 130 y 150. Es un modelo que no está entrenado, es normal que sus fallos sean muy frecuentes en valores altos.
  <h4>Gráfica modelo entrenado 15 epochs</h4>
  <p><img src="https://i.postimg.cc/8CKhdB0W/tej.png" height="600px" width="800px">
  Para este punto concreto tras 15 épocas de entrenamiento los errores son muy frecuentes en valores muy bajos entre 0 y 3. Vemos una gran diferencia con la gráfica anterior. Nuestro modelo ha entrenado correctamente tal y como suponíamos.
  <h2>Conclusión</h2>
  <p>Partimos de un problema inicial donde queríamos obtener datos sobre como nuestra red neuronal estaba entrenando. A pesar de saber que lo normal es que la red neuronal aumente en PCK y disminuya en Error y Loss. Este proyecto nos ha brindado la oportunidad de comprobarlo a escalas de batchs, epochs y experimentos.
  </p>
  <p>Gracias a la herramienta de Power Bi pudimos visualizar de una forma muy dinámica resultados de desempeño de nuestra red para 4 diferentes métodos de optimización. Finalmente tras elegir SGD con Momentum destrozando el supuesto mejor como ADAM. Esto indica que aunque para un exeperimento pasado nos haya servido un método siempre conviene comprobarlo frente a otros métodos.</p>
  <p>Tras elegir el método SGD con Momentum por tener el mejor desempeño adicionalmente usamos python para visualizar la distribución de los errores por punto antes y despues del entrenamiento para apreciar la diferencia.</p>
  <p>Por último comentar que he aprendido mucho sobre herramienas de visualización y sobre métodos de  recopilación de información. Ha sido un experimento muy fructífero que va a servir como previa para el TFM.</p>
</div>
